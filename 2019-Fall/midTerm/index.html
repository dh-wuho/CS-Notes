



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A site for saving CS notes">
      
      
        <link rel="canonical" href="http://csnotes.dhwuho.xyz/2019-Fall/midTerm/">
      
      
        <meta name="author" content="Harry Wu">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.6.0">
    
    
      
        <title>csc522 MidTerm Review - CS Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.1b62728e.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#2196f3">
      
    
    
      <script src="../../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
      <link rel="manifest" href="../../manifest.webmanifest">
    
    
      <link rel="stylesheet" href="../../css/katex.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="blue" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#1-list-explain-and-identify-the-different-types-of-data-attributes-nominal-ordinal-interval-ratio" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="http://csnotes.dhwuho.xyz/" title="CS Notes" class="md-header-nav__button md-logo">
          
            <i class="md-icon">computer</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              CS Notes
            </span>
            <span class="md-header-nav__topic">
              
                csc522 MidTerm Review
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/dh-wuho/CS-Notes/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    dh-wuho/CS-Notes
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="http://csnotes.dhwuho.xyz/" title="CS Notes" class="md-nav__button md-logo">
      
        <i class="md-icon">computer</i>
      
    </a>
    CS Notes
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/dh-wuho/CS-Notes/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    dh-wuho/CS-Notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      2019-Fall
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        2019-Fall
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        csc522 MidTerm Review
      </label>
    
    <a href="./" title="csc522 MidTerm Review" class="md-nav__link md-nav__link--active">
      csc522 MidTerm Review
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-list-explain-and-identify-the-different-types-of-data-attributes-nominal-ordinal-interval-ratio" class="md-nav__link">
    1. List, explain, and identify the different types of data attributes (nominal, ordinal, interval, ratio).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-explain-the-difference-between-supervised-and-unsupervised-learning" class="md-nav__link">
    2. Explain the difference between supervised and unsupervised learning.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-explain-the-nature-and-significance-of-noise-and-outliers-in-data-analysis" class="md-nav__link">
    3. Explain the nature and significance of noise and outliers in data analysis.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-list-explain-compare-and-evaluate-methods-for-handling-missing-data-values" class="md-nav__link">
    4. List, explain, compare, and evaluate methods for handling missing data values.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-explain-the-notion-of-sampling-and-list-and-explain-potential-problems-arising-in-sampling-data-sets" class="md-nav__link">
    5. Explain the notion of sampling, and list and explain potential problems arising in sampling data sets;
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-explain-and-understand-how-principle-component-analysispca-works-and-can-be-applied-to-do-feature-reduction" class="md-nav__link">
    6. Explain and understand how Principle Component Analysis(PCA) works and can be applied to do feature reduction;
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-list-explain-and-compare-different-methods-for-converting-continuous-attributes-into-discrete-attributes" class="md-nav__link">
    7. List, explain, and compare different methods for converting continuous attributes into discrete attributes.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-explain-and-compute-the-mean-median-modes-and-z-scores-of-sets-of-data-values" class="md-nav__link">
    8. Explain and compute the mean, median, modes, and Z-scores of sets of data values.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-explain-the-notion-of-probability-distribution-and-compute-simple-distributions-from-data-frequencies" class="md-nav__link">
    9. Explain the notion of probability distribution and compute simple distributions from data frequencies.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-explain-the-notion-of-conditional-probability-and-compute-conditional-probabilities-from-probability-distributions" class="md-nav__link">
    10. Explain the notion of conditional probability and compute conditional probabilities from probability distributions.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-explain-the-notion-of-correlation-of-data-attributes" class="md-nav__link">
    11. Explain the notion of correlation of data attributes.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-explain-and-give-examples-of-the-notion-of-decision-trees" class="md-nav__link">
    12. Explain and give examples of the notion of decision trees.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-construct-decision-trees-from-small-data-sets-by-using-entropy-and-information-gain" class="md-nav__link">
    13. Construct decision trees from small data sets by using entropy and information gain.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-compare-alternative-splitting-attributes-in-decision-tree-construction-by-applying-gini-or-entropy-measures" class="md-nav__link">
    14. Compare alternative splitting attributes in decision tree construction by applying gini or entropy measures.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-explain-the-problems-caused-by-underfitting-and-overfitting-data-and-by-inexpressive-representations" class="md-nav__link">
    15. Explain the problems caused by underfitting and overfitting data, and by inexpressive representations.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-understand-and-explain-generalization-error-optimistic-error-pessimistic-error-postpruning-based-on-optimistic-error-pessimistic-error" class="md-nav__link">
    16. Understand and explain: generalization error, optimistic error, pessimistic error; postpruning based on optimistic error, pessimistic error.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-how-to-build-decision-trees-with-missing-values-and-apply-the-decision-tree-to-test-data-with-missing-values" class="md-nav__link">
    17. How to build decision trees with missing values and apply the decision tree to test data with missing values.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-chi-square-tests" class="md-nav__link">
    18. Chi-square Tests
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-explain-the-procedure-of-hold-out-stratified-sampling-cross-validation-and-loocv" class="md-nav__link">
    19. Explain the procedure of Hold-out, Stratified Sampling, Cross-Validation, and LOOCV.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-contrast-and-explain-the-notions-of-error-rate-and-confusion-matrices-in-classification" class="md-nav__link">
    20. Contrast and explain the notions of error rate and confusion matrices in classification.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-use-confusion-and-cost-matrices-to-compute-which-of-two-classifiers-is-better-for-a-data-set" class="md-nav__link">
    21. Use confusion and cost matrices to compute which of two classifiers is better for a data set.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#22-explain-the-notion-of-accuracy-error-rate-precision-recall-f-measure" class="md-nav__link">
    22. Explain the notion of Accuracy, Error Rate, Precision, Recall, F-measure.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-explain-the-notion-of-an-roc-curve-auc-and-its-meaning-for-classifier-performance" class="md-nav__link">
    23. Explain the notion of an ROC curve, AUC, and its meaning for classifier performance.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#24-use-roc-curves-to-compare-performance-of-different-classifiers" class="md-nav__link">
    24. Use ROC curves to compare performance of different classifiers.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#25-understanding-the-procedure-of-bagging-and-boosting-especially-the-adaboost" class="md-nav__link">
    25. Understanding the procedure of Bagging and Boosting, especially the Adaboost.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#26-explain-and-understand-how-the-bagging-and-adaboost-works" class="md-nav__link">
    26. Explain and understand how the bagging and AdaBoost works.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#27-explain-how-the-k-nearest-neighbour-classifier-works" class="md-nav__link">
    27. Explain how the K-nearest Neighbour classifier works.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#28-explain-the-notion-of-probabilistic-or-bayesian-methods" class="md-nav__link">
    28. Explain the notion of probabilistic or Bayesian methods.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#29-state-and-explain-bayes-theorem-and-its-use-in-updating-probability-distributions-to-incorporate-new-evidence-and-use-it-to-compute-probabilities" class="md-nav__link">
    29. State and explain Bayes theorem and its use in updating probability distributions to incorporate new evidence, and use it to compute probabilities.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#30-diagram-and-explain-the-naive-bayesian-classification-method" class="md-nav__link">
    30. Diagram and explain the Naive Bayesian classification method.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#31-compute-probabilities-in-small-data-sets-and-use-these-values-in-a-naive-bayesian-classifier-to-classify-data-items" class="md-nav__link">
    31. Compute probabilities in small data sets and use these values in a naive Bayesian classifier to classify data items.
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../finalReview/" title="csc522 Final Review" class="md-nav__link">
      csc522 Final Review
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../csc510-review/" title="csc510 Review" class="md-nav__link">
      csc510 Review
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      CSC568 Enterprise Storage
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        CSC568 Enterprise Storage
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/0-index/" title="Preface" class="md-nav__link">
      Preface
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/10-SAN/" title="10 - SAN" class="md-nav__link">
      10 - SAN
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/11-NAS/" title="11 - NAS" class="md-nav__link">
      11 - NAS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/12-DFS/" title="12 - DFS" class="md-nav__link">
      12 - DFS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/13-Ceph/" title="13 - Ceph" class="md-nav__link">
      13 - Ceph
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/14-GFS/" title="14 - GFS" class="md-nav__link">
      14 - GFS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/15-LFS/" title="15 - LFS" class="md-nav__link">
      15 - LFS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/16-Redundancy/" title="16 - Redundancy" class="md-nav__link">
      16 - Redundancy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/17-Deduplication/" title="17 - Deduplication" class="md-nav__link">
      17 - Deduplication
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/18-GNR/" title="18 - GNR" class="md-nav__link">
      18 - GNR
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/19-Erasure-Encoding/" title="19 - Erasure Encoding" class="md-nav__link">
      19 - Erasure Encoding
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/20-Business-Continuity/" title="20 - Business Continuity" class="md-nav__link">
      20 - Business Continuity
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/21-SCM/" title="21 - SCM" class="md-nav__link">
      21 - SCM
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/23-Haystack/" title="23 - Haystack" class="md-nav__link">
      23 - Haystack
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/24-Disasters/" title="24 - Disasters" class="md-nav__link">
      24 - Disasters
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/25-DevFS/" title="25 - DevFS" class="md-nav__link">
      25 - DevFS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../csc568/26-SSD-Reliability/" title="26 - SSD Reliability" class="md-nav__link">
      26 - SSD Reliability
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-list-explain-and-identify-the-different-types-of-data-attributes-nominal-ordinal-interval-ratio" class="md-nav__link">
    1. List, explain, and identify the different types of data attributes (nominal, ordinal, interval, ratio).
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-explain-the-difference-between-supervised-and-unsupervised-learning" class="md-nav__link">
    2. Explain the difference between supervised and unsupervised learning.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-explain-the-nature-and-significance-of-noise-and-outliers-in-data-analysis" class="md-nav__link">
    3. Explain the nature and significance of noise and outliers in data analysis.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-list-explain-compare-and-evaluate-methods-for-handling-missing-data-values" class="md-nav__link">
    4. List, explain, compare, and evaluate methods for handling missing data values.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-explain-the-notion-of-sampling-and-list-and-explain-potential-problems-arising-in-sampling-data-sets" class="md-nav__link">
    5. Explain the notion of sampling, and list and explain potential problems arising in sampling data sets;
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-explain-and-understand-how-principle-component-analysispca-works-and-can-be-applied-to-do-feature-reduction" class="md-nav__link">
    6. Explain and understand how Principle Component Analysis(PCA) works and can be applied to do feature reduction;
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-list-explain-and-compare-different-methods-for-converting-continuous-attributes-into-discrete-attributes" class="md-nav__link">
    7. List, explain, and compare different methods for converting continuous attributes into discrete attributes.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-explain-and-compute-the-mean-median-modes-and-z-scores-of-sets-of-data-values" class="md-nav__link">
    8. Explain and compute the mean, median, modes, and Z-scores of sets of data values.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-explain-the-notion-of-probability-distribution-and-compute-simple-distributions-from-data-frequencies" class="md-nav__link">
    9. Explain the notion of probability distribution and compute simple distributions from data frequencies.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-explain-the-notion-of-conditional-probability-and-compute-conditional-probabilities-from-probability-distributions" class="md-nav__link">
    10. Explain the notion of conditional probability and compute conditional probabilities from probability distributions.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-explain-the-notion-of-correlation-of-data-attributes" class="md-nav__link">
    11. Explain the notion of correlation of data attributes.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-explain-and-give-examples-of-the-notion-of-decision-trees" class="md-nav__link">
    12. Explain and give examples of the notion of decision trees.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-construct-decision-trees-from-small-data-sets-by-using-entropy-and-information-gain" class="md-nav__link">
    13. Construct decision trees from small data sets by using entropy and information gain.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-compare-alternative-splitting-attributes-in-decision-tree-construction-by-applying-gini-or-entropy-measures" class="md-nav__link">
    14. Compare alternative splitting attributes in decision tree construction by applying gini or entropy measures.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-explain-the-problems-caused-by-underfitting-and-overfitting-data-and-by-inexpressive-representations" class="md-nav__link">
    15. Explain the problems caused by underfitting and overfitting data, and by inexpressive representations.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-understand-and-explain-generalization-error-optimistic-error-pessimistic-error-postpruning-based-on-optimistic-error-pessimistic-error" class="md-nav__link">
    16. Understand and explain: generalization error, optimistic error, pessimistic error; postpruning based on optimistic error, pessimistic error.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-how-to-build-decision-trees-with-missing-values-and-apply-the-decision-tree-to-test-data-with-missing-values" class="md-nav__link">
    17. How to build decision trees with missing values and apply the decision tree to test data with missing values.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-chi-square-tests" class="md-nav__link">
    18. Chi-square Tests
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-explain-the-procedure-of-hold-out-stratified-sampling-cross-validation-and-loocv" class="md-nav__link">
    19. Explain the procedure of Hold-out, Stratified Sampling, Cross-Validation, and LOOCV.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-contrast-and-explain-the-notions-of-error-rate-and-confusion-matrices-in-classification" class="md-nav__link">
    20. Contrast and explain the notions of error rate and confusion matrices in classification.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-use-confusion-and-cost-matrices-to-compute-which-of-two-classifiers-is-better-for-a-data-set" class="md-nav__link">
    21. Use confusion and cost matrices to compute which of two classifiers is better for a data set.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#22-explain-the-notion-of-accuracy-error-rate-precision-recall-f-measure" class="md-nav__link">
    22. Explain the notion of Accuracy, Error Rate, Precision, Recall, F-measure.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-explain-the-notion-of-an-roc-curve-auc-and-its-meaning-for-classifier-performance" class="md-nav__link">
    23. Explain the notion of an ROC curve, AUC, and its meaning for classifier performance.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#24-use-roc-curves-to-compare-performance-of-different-classifiers" class="md-nav__link">
    24. Use ROC curves to compare performance of different classifiers.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#25-understanding-the-procedure-of-bagging-and-boosting-especially-the-adaboost" class="md-nav__link">
    25. Understanding the procedure of Bagging and Boosting, especially the Adaboost.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#26-explain-and-understand-how-the-bagging-and-adaboost-works" class="md-nav__link">
    26. Explain and understand how the bagging and AdaBoost works.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#27-explain-how-the-k-nearest-neighbour-classifier-works" class="md-nav__link">
    27. Explain how the K-nearest Neighbour classifier works.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#28-explain-the-notion-of-probabilistic-or-bayesian-methods" class="md-nav__link">
    28. Explain the notion of probabilistic or Bayesian methods.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#29-state-and-explain-bayes-theorem-and-its-use-in-updating-probability-distributions-to-incorporate-new-evidence-and-use-it-to-compute-probabilities" class="md-nav__link">
    29. State and explain Bayes theorem and its use in updating probability distributions to incorporate new evidence, and use it to compute probabilities.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#30-diagram-and-explain-the-naive-bayesian-classification-method" class="md-nav__link">
    30. Diagram and explain the Naive Bayesian classification method.
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#31-compute-probabilities-in-small-data-sets-and-use-these-values-in-a-naive-bayesian-classifier-to-classify-data-items" class="md-nav__link">
    31. Compute probabilities in small data sets and use these values in a naive Bayesian classifier to classify data items.
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/dh-wuho/CS-Notes/edit/master/docs/2019-Fall/midTerm.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                  <h1>csc522 MidTerm Review</h1>
                
                <h4 id="1-list-explain-and-identify-the-different-types-of-data-attributes-nominal-ordinal-interval-ratio">1. List, explain, and identify the different types of data attributes (nominal, ordinal, interval, ratio).</h4>
<p>Nominal: ==, !=</p>
<p>Ordinal: ==, !=, &lt;, &gt;, &lt;=, &gt;=</p>
<p>Interval: ==, !=, &lt;, &gt;, &lt;=, &gt;=, +, -</p>
<p>Ratio: ==, !=, &lt;, &gt;, &lt;=, &gt;=, +, -, *, /</p>
<h4 id="2-explain-the-difference-between-supervised-and-unsupervised-learning">2. Explain the difference between supervised and unsupervised learning.</h4>
<p>Supervised: feature X with Label Y to predict(Regression, Classification).</p>
<p>Unsupervised: feature X to learn itself to describe(Density estimation, Clustering, Dimensionality reduction).</p>
<h4 id="3-explain-the-nature-and-significance-of-noise-and-outliers-in-data-analysis">3. Explain the nature and significance of noise and outliers in data analysis.</h4>
<p>Noise refers to modification of original values.</p>
<p>Outliers are data objects with characteristics that are considerably different than most of the other data objects in the data set.</p>
<h4 id="4-list-explain-compare-and-evaluate-methods-for-handling-missing-data-values">4. List, explain, compare, and evaluate methods for handling missing data values.</h4>
<p>Eliminate Data Objects: straightforward to implement, but signicantly limits the scope and power of study, and introduces bias when data is not missing at random.</p>
<p>Estimate Missing Values: Comparing to complete-case analysis, it can utilize all present data for analysis. However, some data imputation methods are only suitable when missing rate is low, e.g. mean- or median-lling and knn.</p>
<p>Ignore the Missing Value During Analysis.</p>
<p>Replace with all possible values(weighted by probabilities)</p>
<h4 id="5-explain-the-notion-of-sampling-and-list-and-explain-potential-problems-arising-in-sampling-data-sets">5. Explain the notion of sampling, and list and explain potential problems arising in sampling data sets;</h4>
<p>Sampling is the use of a subset of the population to represent the whole population.</p>
<p>Two key principles for effective sampling:
- using a sample will work almost as well as using the entire data sets, if the sample is representative.</p>
<ul>
<li>A sample is representative if it has approximately the same property as the original set of data.</li>
</ul>
<h4 id="6-explain-and-understand-how-principle-component-analysispca-works-and-can-be-applied-to-do-feature-reduction">6. Explain and understand how Principle Component Analysis(PCA) works and can be applied to do feature reduction;</h4>
<p>When applying PCA, the resulted principle components are always orthogonal(perpendicular) to one another.</p>
<p>When applying PCA, each of principal components is always a linear combination of the original features.</p>
<h4 id="7-list-explain-and-compare-different-methods-for-converting-continuous-attributes-into-discrete-attributes">7. List, explain, and compare different methods for converting continuous attributes into discrete attributes.</h4>
<p>Discretization</p>
<p>Attributes Transformation</p>
<h4 id="8-explain-and-compute-the-mean-median-modes-and-z-scores-of-sets-of-data-values">8. Explain and compute the mean, median, modes, and Z-scores of sets of data values.</h4>
<p>Frequency(频率或频数): </p>
<p>Mean(平均数): very sensitive to outliers</p>
<p>Median(中位数): Summary of frequency distribution</p>
<p>Modes(众数):</p>
<p>Z-scores: the standard score is the signed fractional number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.</p>
<p>$$Z-scores = (oneData - mean) / standardDeviation$$</p>
<h4 id="9-explain-the-notion-of-probability-distribution-and-compute-simple-distributions-from-data-frequencies">9. Explain the notion of probability distribution and compute simple distributions from data frequencies.</h4>
<h4 id="10-explain-the-notion-of-conditional-probability-and-compute-conditional-probabilities-from-probability-distributions">10. Explain the notion of conditional probability and compute conditional probabilities from probability distributions.</h4>
<h4 id="11-explain-the-notion-of-correlation-of-data-attributes">11. Explain the notion of correlation of data attributes.</h4>
<p>Correlation measures the linear relationship between objects.</p>
<p>Variance – measure of the deviation from the mean for points in one dimension.</p>
<p>Covariance – a measure of how much each of the dimensions varies from the mean with respect to each other.</p>
<p>$$Correlation(X, Y) = \frac{Covariance(X, Y)}{Variance(X)Variance(Y)}$$</p>
<h4 id="12-explain-and-give-examples-of-the-notion-of-decision-trees">12. Explain and give examples of the notion of decision trees.</h4>
<p>Given a collection of records (training set ): Each record contains a set of attributes, one of the attributes is the class. (Categorical, discrete, unordered) Find a model for class attribute as a function of the values of other attributes.</p>
<p>Goal: previously unseen records (test set) should be assigned a class as accurately as possible.</p>
<h4 id="13-construct-decision-trees-from-small-data-sets-by-using-entropy-and-information-gain">13. Construct decision trees from small data sets by using entropy and information gain.</h4>
<h4 id="14-compare-alternative-splitting-attributes-in-decision-tree-construction-by-applying-gini-or-entropy-measures">14. Compare alternative splitting attributes in decision tree construction by applying gini or entropy measures.</h4>
<h4 id="15-explain-the-problems-caused-by-underfitting-and-overfitting-data-and-by-inexpressive-representations">15. Explain the problems caused by underfitting and overfitting data, and by inexpressive representations.</h4>
<p>Underfitting: when model is too simple, both training and test errors are large.</p>
<p>Overfitting: when model is complex where training error is small but test error is large.</p>
<h4 id="16-understand-and-explain-generalization-error-optimistic-error-pessimistic-error-postpruning-based-on-optimistic-error-pessimistic-error">16. Understand and explain: generalization error, optimistic error, pessimistic error; postpruning based on optimistic error, pessimistic error.</h4>
<p>Generalization error: Generalization error is the true error for the population of examples we would like to optimize.</p>
<p>Optimistic error:</p>
<p>Pessimistic:</p>
<h4 id="17-how-to-build-decision-trees-with-missing-values-and-apply-the-decision-tree-to-test-data-with-missing-values">17. How to build decision trees with missing values and apply the decision tree to test data with missing values.</h4>
<h4 id="18-chi-square-tests">18. Chi-square Tests</h4>
<p>$$X^2 = \sum{\frac{O_i - E_i}{E_i}}$$</p>
<p>O is pratical value.</p>
<p>E is theoretical value.</p>
<h4 id="19-explain-the-procedure-of-hold-out-stratified-sampling-cross-validation-and-loocv">19. Explain the procedure of Hold-out, Stratified Sampling, Cross-Validation, and LOOCV.</h4>
<p>Holdout: 2/3 for training and 1/3 for testing.</p>
<p>Stratified Sampling: sample in such a way that each class is represented in both sets.</p>
<p>Cross-Validation</p>
<p>LOOCV</p>
<h4 id="20-contrast-and-explain-the-notions-of-error-rate-and-confusion-matrices-in-classification">20. Contrast and explain the notions of error rate and confusion matrices in classification.</h4>
<h4 id="21-use-confusion-and-cost-matrices-to-compute-which-of-two-classifiers-is-better-for-a-data-set">21. Use confusion and cost matrices to compute which of two classifiers is better for a data set.</h4>
<h4 id="22-explain-the-notion-of-accuracy-error-rate-precision-recall-f-measure">22. Explain the notion of Accuracy, Error Rate, Precision, Recall, F-measure.</h4>
<p>$$Accuracy = \frac{TP+TN}{TP+FP+TN+FN}$$
$$Error Rate = 1 - Accuracy$$
$$Precision(p) = \frac{TP}{TP+FP}$$
$$Recall(r) = \frac{TP}{TP+FN}$$
$$F-Measure(F) = \frac{2rp}{r+p} = \frac{2TP}{2TP+FP+FN}$$</p>
<p>The Accuracy (or error rate=1-Accuracy) is an inadequate measure of the performance of an algorithm, it doesn’t take into account the cost of making wrong decisions.</p>
<h4 id="23-explain-the-notion-of-an-roc-curve-auc-and-its-meaning-for-classifier-performance">23. Explain the notion of an ROC curve, AUC, and its meaning for classifier performance.</h4>
<h4 id="24-use-roc-curves-to-compare-performance-of-different-classifiers">24. Use ROC curves to compare performance of different classifiers.</h4>
<h4 id="25-understanding-the-procedure-of-bagging-and-boosting-especially-the-adaboost">25. Understanding the procedure of Bagging and Boosting, especially the Adaboost.</h4>
<h4 id="26-explain-and-understand-how-the-bagging-and-adaboost-works">26. Explain and understand how the bagging and AdaBoost works.</h4>
<h4 id="27-explain-how-the-k-nearest-neighbour-classifier-works">27. Explain how the K-nearest Neighbour classifier works.</h4>
<h4 id="28-explain-the-notion-of-probabilistic-or-bayesian-methods">28. Explain the notion of probabilistic or Bayesian methods.</h4>
<h4 id="29-state-and-explain-bayes-theorem-and-its-use-in-updating-probability-distributions-to-incorporate-new-evidence-and-use-it-to-compute-probabilities">29. State and explain Bayes theorem and its use in updating probability distributions to incorporate new evidence, and use it to compute probabilities.</h4>
<h4 id="30-diagram-and-explain-the-naive-bayesian-classification-method">30. Diagram and explain the Naive Bayesian classification method.</h4>
<h4 id="31-compute-probabilities-in-small-data-sets-and-use-these-values-in-a-naive-bayesian-classifier-to-classify-data-items">31. Compute probabilities in small data sets and use these values in a naive Bayesian classifier to classify data items.</h4>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../.." title="Home" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Home
              </span>
            </div>
          </a>
        
        
          <a href="../finalReview/" title="csc522 Final Review" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                csc522 Final Review
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2018 - 2019 dhwuho
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.808e90bb.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="../../js/katex.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>